{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGluon Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/axelsariel/repos/HousingDemographics/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "binaryDf = TabularDataset('binary_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GrowthRate\n",
       " 1.0    0.862346\n",
       " 0.0    0.071063\n",
       "-1.0    0.066591\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(binaryDf, test_size=0.25, random_state=0)\n",
    "label = 'GrowthRate'\n",
    "train_data[label].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240429_191124\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240429_191124\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.11.6\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 23.0.0: Fri Sep 15 14:42:42 PDT 2023; root:xnu-10002.1.13~1/RELEASE_X86_64\n",
      "CPU Count:          8\n",
      "Memory Avail:       5.94 GB / 16.00 GB (37.1%)\n",
      "Disk Space Avail:   6.54 GB / 371.60 GB (1.8%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Train Data Rows:    187594\n",
      "Train Data Columns: 6\n",
      "Label Column:       GrowthRate\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\t3 unique label values:  [1.0, 0.0, -1.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6091.94 MB\n",
      "\tTrain Data (Original)  Memory Usage: 8.59 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['WHITE', 'BLACK_OR_AFRICAN_AMERICAN', 'AMERICAN_INDIAN_AND_ALASKA_NATIVE', 'ASIAN', 'NATIVE_HAWAIIAN_AND_OTHER_PACIFIC_ISLANDER', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['WHITE', 'BLACK_OR_AFRICAN_AMERICAN', 'AMERICAN_INDIAN_AND_ALASKA_NATIVE', 'ASIAN', 'NATIVE_HAWAIIAN_AND_OTHER_PACIFIC_ISLANDER', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t6 features in original data used to generate 6 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.59 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.35s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01332665223834451, Train Rows: 185094, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 299.65s of the 299.65s of remaining time.\n",
      "\t0.828\t = Validation score   (accuracy)\n",
      "\t3.32s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 296.08s of the 296.07s of remaining time.\n",
      "\t0.828\t = Validation score   (accuracy)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 295.53s of the 295.52s of remaining time.\n",
      "No improvement since epoch 0: early stopping\n",
      "\t0.8624\t = Validation score   (accuracy)\n",
      "\t119.19s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 176.19s of the 176.19s of remaining time.\n",
      "\tWarning: Exception caused LightGBMXT to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/axelsariel/repos/HousingDemographics/venv/lib/python3.11/site-packages/lightgbm/lib/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <C3EB28DD-60B6-3334-AFA2-72BBBF9DBAEF> /Users/axelsariel/repos/HousingDemographics/venv/lib/python3.11/site-packages/lightgbm/lib/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM ... Training model for up to 175.71s of the 175.71s of remaining time.\n",
      "\tWarning: Exception caused LightGBM to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/axelsariel/repos/HousingDemographics/venv/lib/python3.11/site-packages/lightgbm/lib/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <C3EB28DD-60B6-3334-AFA2-72BBBF9DBAEF> /Users/axelsariel/repos/HousingDemographics/venv/lib/python3.11/site-packages/lightgbm/lib/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestGini ... Training model for up to 175.57s of the 175.57s of remaining time.\n",
      "\t0.8624\t = Validation score   (accuracy)\n",
      "\t8.11s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 167.14s of the 167.13s of remaining time.\n",
      "\t0.8624\t = Validation score   (accuracy)\n",
      "\t7.05s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 159.71s of the 159.71s of remaining time.\n",
      "\tWarning: Exception caused CatBoost to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 159.56s of the 159.55s of remaining time.\n",
      "\t0.8624\t = Validation score   (accuracy)\n",
      "\t6.09s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 153.12s of the 153.12s of remaining time.\n",
      "\t0.8624\t = Validation score   (accuracy)\n",
      "\t5.94s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 146.78s of the 146.78s of remaining time.\n",
      "\t0.8624\t = Validation score   (accuracy)\n",
      "\t1.15s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 145.62s of the 145.62s of remaining time.\n",
      "\t0.8624\t = Validation score   (accuracy)\n",
      "\t63.25s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 82.35s of the 82.35s of remaining time.\n",
      "\tWarning: Exception caused LightGBMLarge to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/axelsariel/repos/HousingDemographics/venv/lib/python3.11/site-packages/lightgbm/lib/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <C3EB28DD-60B6-3334-AFA2-72BBBF9DBAEF> /Users/axelsariel/repos/HousingDemographics/venv/lib/python3.11/site-packages/lightgbm/lib/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.65s of the 82.18s of remaining time.\n",
      "\tEnsemble Weights: {'ExtraTreesEntr': 1.0}\n",
      "\t0.8624\t = Validation score   (accuracy)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 218.06s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240429_191124\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label).fit(train_data, time_limit=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11553     1.0\n",
       "1177      1.0\n",
       "3111      1.0\n",
       "111294    1.0\n",
       "173138    1.0\n",
       "Name: GrowthRate, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data.drop(columns=[label]))\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    62532.0\n",
       "mean         1.0\n",
       "std          0.0\n",
       "min          1.0\n",
       "25%          1.0\n",
       "50%          1.0\n",
       "75%          1.0\n",
       "max          1.0\n",
       "Name: GrowthRate, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8622945052133307,\n",
       " 'balanced_accuracy': 0.3333333333333333,\n",
       " 'mcc': 0.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241m.\u001b[39mleaderboard(test_data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.feature_importance(train_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
