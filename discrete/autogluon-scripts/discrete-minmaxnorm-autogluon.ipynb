{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGluon Discrete MinMaxNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/axelsariel/repos/HousingDemographics/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "discreteDf = TabularDataset('../discrete_minmaxnorm_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    187594.000000\n",
       "mean          0.037885\n",
       "std           0.021942\n",
       "min           0.000000\n",
       "25%           0.033898\n",
       "50%           0.036268\n",
       "75%           0.039685\n",
       "max           1.000000\n",
       "Name: GrowthRate, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(discreteDf, test_size=0.25, random_state=0)\n",
    "label = 'GrowthRate'\n",
    "train_data[label].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240429_202529\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240429_202529\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.11.6\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 23.0.0: Fri Sep 15 14:42:42 PDT 2023; root:xnu-10002.1.13~1/RELEASE_X86_64\n",
      "CPU Count:          8\n",
      "Memory Avail:       6.15 GB / 16.00 GB (38.4%)\n",
      "Disk Space Avail:   4.92 GB / 371.60 GB (1.3%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Train Data Rows:    187594\n",
      "Train Data Columns: 6\n",
      "Label Column:       GrowthRate\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1.0, 0.0, 0.03789, 0.02194)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6278.45 MB\n",
      "\tTrain Data (Original)  Memory Usage: 8.59 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['WHITE', 'BLACK_OR_AFRICAN_AMERICAN', 'AMERICAN_INDIAN_AND_ALASKA_NATIVE', 'ASIAN', 'NATIVE_HAWAIIAN_AND_OTHER_PACIFIC_ISLANDER', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['WHITE', 'BLACK_OR_AFRICAN_AMERICAN', 'AMERICAN_INDIAN_AND_ALASKA_NATIVE', 'ASIAN', 'NATIVE_HAWAIIAN_AND_OTHER_PACIFIC_ISLANDER', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t6 features in original data used to generate 6 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.59 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.33s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01332665223834451, Train Rows: 185094, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 299.67s of the 299.67s of remaining time.\n",
      "\t-0.0287\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.72s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 295.76s of the 295.75s of remaining time.\n",
      "\t-0.0289\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 295.28s of the 295.28s of remaining time.\n",
      "\tWarning: Exception caused LightGBMXT to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/axelsariel/repos/HousingDemographics/venv/lib/python3.11/site-packages/lightgbm/lib/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <C3EB28DD-60B6-3334-AFA2-72BBBF9DBAEF> /Users/axelsariel/repos/HousingDemographics/venv/lib/python3.11/site-packages/lightgbm/lib/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM ... Training model for up to 294.75s of the 294.75s of remaining time.\n",
      "\tWarning: Exception caused LightGBM to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/axelsariel/repos/HousingDemographics/venv/lib/python3.11/site-packages/lightgbm/lib/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <C3EB28DD-60B6-3334-AFA2-72BBBF9DBAEF> /Users/axelsariel/repos/HousingDemographics/venv/lib/python3.11/site-packages/lightgbm/lib/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE ... Training model for up to 294.62s of the 294.62s of remaining time.\n",
      "\t-0.028\t = Validation score   (-root_mean_squared_error)\n",
      "\t60.52s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 230.9s of the 230.9s of remaining time.\n",
      "\tWarning: Exception caused CatBoost to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 230.77s of the 230.77s of remaining time.\n",
      "\t-0.0271\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.62s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 212.84s of the 212.84s of remaining time.\n",
      "\t-0.0265\t = Validation score   (-root_mean_squared_error)\n",
      "\t165.08s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 47.57s of the 47.57s of remaining time.\n",
      "\t-0.0265\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 47.05s of the 47.04s of remaining time.\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 15)\n",
      "\t-0.0265\t = Validation score   (-root_mean_squared_error)\n",
      "\t46.06s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.67s of the 0.95s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 0.333, 'NeuralNetTorch': 0.333, 'XGBoost': 0.267, 'ExtraTreesMSE': 0.067}\n",
      "\t-0.0265\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 299.12s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240429_202529\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label).fit(train_data, time_limit=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11553     0.037793\n",
       "1177      0.037845\n",
       "3111      0.038365\n",
       "111294    0.037937\n",
       "173138    0.038022\n",
       "Name: GrowthRate, dtype: float32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data.drop(columns=[label]))\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    62532.000000\n",
       "mean         0.038079\n",
       "std          0.000735\n",
       "min          0.025833\n",
       "25%          0.037669\n",
       "50%          0.037868\n",
       "75%          0.038247\n",
       "max          0.077946\n",
       "Name: GrowthRate, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': -0.022866577855627946,\n",
       " 'mean_squared_error': -0.0005228803828274943,\n",
       " 'mean_absolute_error': -0.004755569380020216,\n",
       " 'r2': 0.0012429774417439532,\n",
       " 'pearsonr': 0.03625260587273514,\n",
       " 'median_absolute_error': -0.003287918122844402}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>-0.022865</td>\n",
       "      <td>-0.026536</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.256191</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>46.057592</td>\n",
       "      <td>0.256191</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>46.057592</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.022867</td>\n",
       "      <td>-0.026528</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>3.164597</td>\n",
       "      <td>0.141703</td>\n",
       "      <td>226.287505</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.011888</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-0.022882</td>\n",
       "      <td>-0.026537</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.771587</td>\n",
       "      <td>0.036879</td>\n",
       "      <td>165.084605</td>\n",
       "      <td>0.771587</td>\n",
       "      <td>0.036879</td>\n",
       "      <td>165.084605</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-0.022884</td>\n",
       "      <td>-0.026535</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.025305</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.512291</td>\n",
       "      <td>0.025305</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.512291</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-0.023553</td>\n",
       "      <td>-0.027112</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2.107817</td>\n",
       "      <td>0.083556</td>\n",
       "      <td>14.621129</td>\n",
       "      <td>2.107817</td>\n",
       "      <td>0.083556</td>\n",
       "      <td>14.621129</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-0.023966</td>\n",
       "      <td>-0.028009</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2.570022</td>\n",
       "      <td>0.086254</td>\n",
       "      <td>60.520135</td>\n",
       "      <td>2.570022</td>\n",
       "      <td>0.086254</td>\n",
       "      <td>60.520135</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-0.024914</td>\n",
       "      <td>-0.028690</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2.601300</td>\n",
       "      <td>0.138497</td>\n",
       "      <td>3.716463</td>\n",
       "      <td>2.601300</td>\n",
       "      <td>0.138497</td>\n",
       "      <td>3.716463</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-0.025859</td>\n",
       "      <td>-0.028923</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2.289892</td>\n",
       "      <td>0.096366</td>\n",
       "      <td>0.286194</td>\n",
       "      <td>2.289892</td>\n",
       "      <td>0.096366</td>\n",
       "      <td>0.286194</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val              eval_metric  \\\n",
       "0       NeuralNetTorch   -0.022865  -0.026536  root_mean_squared_error   \n",
       "1  WeightedEnsemble_L2   -0.022867  -0.026528  root_mean_squared_error   \n",
       "2      NeuralNetFastAI   -0.022882  -0.026537  root_mean_squared_error   \n",
       "3              XGBoost   -0.022884  -0.026535  root_mean_squared_error   \n",
       "4        ExtraTreesMSE   -0.023553  -0.027112  root_mean_squared_error   \n",
       "5      RandomForestMSE   -0.023966  -0.028009  root_mean_squared_error   \n",
       "6       KNeighborsUnif   -0.024914  -0.028690  root_mean_squared_error   \n",
       "7       KNeighborsDist   -0.025859  -0.028923  root_mean_squared_error   \n",
       "\n",
       "   pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  \\\n",
       "0        0.256191       0.016908   46.057592                 0.256191   \n",
       "1        3.164597       0.141703  226.287505                 0.003697   \n",
       "2        0.771587       0.036879  165.084605                 0.771587   \n",
       "3        0.025305       0.003753    0.512291                 0.025305   \n",
       "4        2.107817       0.083556   14.621129                 2.107817   \n",
       "5        2.570022       0.086254   60.520135                 2.570022   \n",
       "6        2.601300       0.138497    3.716463                 2.601300   \n",
       "7        2.289892       0.096366    0.286194                 2.289892   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.016908          46.057592            1       True   \n",
       "1                0.000607           0.011888            2       True   \n",
       "2                0.036879         165.084605            1       True   \n",
       "3                0.003753           0.512291            1       True   \n",
       "4                0.083556          14.621129            1       True   \n",
       "5                0.086254          60.520135            1       True   \n",
       "6                0.138497           3.716463            1       True   \n",
       "7                0.096366           0.286194            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          7  \n",
       "1          8  \n",
       "2          5  \n",
       "3          6  \n",
       "4          4  \n",
       "5          3  \n",
       "6          1  \n",
       "7          2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 6 features using 5000 rows with 5 shuffle sets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t41.87s\t= Expected runtime (8.37s per shuffle set)\n",
      "\t16.05s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WHITE</th>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>2.955595e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HISPANIC_OR_LATINO</th>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>1.910613e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLACK_OR_AFRICAN_AMERICAN</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>2.440826e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASIAN</th>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>9.134509e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMERICAN_INDIAN_AND_ALASKA_NATIVE</th>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>-6.979293e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NATIVE_HAWAIIAN_AND_OTHER_PACIFIC_ISLANDER</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>3.407208e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            importance    stddev   p_value  n  \\\n",
       "WHITE                                         0.000507  0.000103  0.000191  5   \n",
       "HISPANIC_OR_LATINO                            0.000471  0.000136  0.000747  5   \n",
       "BLACK_OR_AFRICAN_AMERICAN                     0.000412  0.000082  0.000175  5   \n",
       "ASIAN                                         0.000383  0.000141  0.001885  5   \n",
       "AMERICAN_INDIAN_AND_ALASKA_NATIVE             0.000232  0.000147  0.012002  5   \n",
       "NATIVE_HAWAIIAN_AND_OTHER_PACIFIC_ISLANDER    0.000009  0.000004  0.004374  5   \n",
       "\n",
       "                                            p99_high       p99_low  \n",
       "WHITE                                       0.000718  2.955595e-04  \n",
       "HISPANIC_OR_LATINO                          0.000750  1.910613e-04  \n",
       "BLACK_OR_AFRICAN_AMERICAN                   0.000580  2.440826e-04  \n",
       "ASIAN                                       0.000674  9.134509e-05  \n",
       "AMERICAN_INDIAN_AND_ALASKA_NATIVE           0.000534 -6.979293e-05  \n",
       "NATIVE_HAWAIIAN_AND_OTHER_PACIFIC_ISLANDER  0.000018  3.407208e-07  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(train_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
