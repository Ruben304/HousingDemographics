{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGluon Decimal MeanNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/axelsariel/repos/HousingDemographics/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "decimalDf = TabularDataset('../decimal_meannorm_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    187594.000000\n",
       "mean         -0.000289\n",
       "std           0.989245\n",
       "min          -1.708357\n",
       "25%          -0.180039\n",
       "50%          -0.073180\n",
       "75%           0.080838\n",
       "max          43.377082\n",
       "Name: GrowthRate, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(decimalDf, test_size=0.25, random_state=0)\n",
    "label = 'GrowthRate'\n",
    "train_data[label].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240429_205432\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240429_205432\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.11.6\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 23.0.0: Fri Sep 15 14:42:42 PDT 2023; root:xnu-10002.1.13~1/RELEASE_X86_64\n",
      "CPU Count:          8\n",
      "Memory Avail:       5.46 GB / 16.00 GB (34.1%)\n",
      "Disk Space Avail:   3.62 GB / 371.60 GB (1.0%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Train Data Rows:    187594\n",
      "Train Data Columns: 6\n",
      "Label Column:       GrowthRate\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (43.37708168786803, -1.7083573243819408, -0.00029, 0.98925)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5586.62 MB\n",
      "\tTrain Data (Original)  Memory Usage: 8.59 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['WHITE', 'BLACK_OR_AFRICAN_AMERICAN', 'AMERICAN_INDIAN_AND_ALASKA_NATIVE', 'ASIAN', 'NATIVE_HAWAIIAN_AND_OTHER_PACIFIC_ISLANDER', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['WHITE', 'BLACK_OR_AFRICAN_AMERICAN', 'AMERICAN_INDIAN_AND_ALASKA_NATIVE', 'ASIAN', 'NATIVE_HAWAIIAN_AND_OTHER_PACIFIC_ISLANDER', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t6 features in original data used to generate 6 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.59 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.35s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01332665223834451, Train Rows: 185094, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 299.65s of the 299.65s of remaining time.\n",
      "\t-1.2922\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.96s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 296.44s of the 296.44s of remaining time.\n",
      "\t-1.3078\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 295.94s of the 295.94s of remaining time.\n",
      "\tWarning: Exception caused LightGBMXT to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/axelsariel/repos/HousingDemographics/venv/lib/python3.11/site-packages/lightgbm/lib/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <C3EB28DD-60B6-3334-AFA2-72BBBF9DBAEF> /Users/axelsariel/repos/HousingDemographics/venv/lib/python3.11/site-packages/lightgbm/lib/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM ... Training model for up to 295.47s of the 295.47s of remaining time.\n",
      "\tWarning: Exception caused LightGBM to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/axelsariel/repos/HousingDemographics/venv/lib/python3.11/site-packages/lightgbm/lib/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <C3EB28DD-60B6-3334-AFA2-72BBBF9DBAEF> /Users/axelsariel/repos/HousingDemographics/venv/lib/python3.11/site-packages/lightgbm/lib/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestMSE ... Training model for up to 295.34s of the 295.34s of remaining time.\n",
      "\t-1.2621\t = Validation score   (-root_mean_squared_error)\n",
      "\t71.74s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 219.22s of the 219.21s of remaining time.\n",
      "\tWarning: Exception caused CatBoost to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 219.09s of the 219.08s of remaining time.\n",
      "\t-1.233\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.15s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 199.56s of the 199.56s of remaining time.\n",
      "\t-1.1964\t = Validation score   (-root_mean_squared_error)\n",
      "\t154.28s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 45.1s of the 45.1s of remaining time.\n",
      "\t-1.1962\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 44.68s of the 44.68s of remaining time.\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 16)\n",
      "\t-1.1963\t = Validation score   (-root_mean_squared_error)\n",
      "\t43.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.65s of the 1.64s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 0.4, 'XGBoost': 0.32, 'NeuralNetFastAI': 0.24, 'KNeighborsDist': 0.04}\n",
      "\t-1.196\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 298.46s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240429_205432\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label).fit(train_data, time_limit=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11553    -0.000357\n",
       "1177     -0.001643\n",
       "3111      0.021981\n",
       "111294    0.002375\n",
       "173138   -0.000222\n",
       "Name: GrowthRate, dtype: float32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data.drop(columns=[label]))\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    62532.000000\n",
       "mean         0.006129\n",
       "std          0.039093\n",
       "min         -0.369202\n",
       "25%         -0.013407\n",
       "50%         -0.003491\n",
       "75%          0.012938\n",
       "max          3.298487\n",
       "Name: GrowthRate, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': -1.0310148294979298,\n",
       " 'mean_squared_error': -1.062991578644645,\n",
       " 'mean_absolute_error': -0.21349963611158437,\n",
       " 'r2': 0.0011167845327497705,\n",
       " 'pearsonr': 0.034026198794335064,\n",
       " 'median_absolute_error': -0.14660948682302}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>-1.030848</td>\n",
       "      <td>-1.196313</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.249814</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>43.001672</td>\n",
       "      <td>0.249814</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>43.001672</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-1.031015</td>\n",
       "      <td>-1.195992</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>4.022845</td>\n",
       "      <td>0.182707</td>\n",
       "      <td>198.020059</td>\n",
       "      <td>0.004716</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.011728</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-1.031634</td>\n",
       "      <td>-1.196416</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.739340</td>\n",
       "      <td>0.033155</td>\n",
       "      <td>154.282954</td>\n",
       "      <td>0.739340</td>\n",
       "      <td>0.033155</td>\n",
       "      <td>154.282954</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-1.032005</td>\n",
       "      <td>-1.196237</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>0.411694</td>\n",
       "      <td>0.024865</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>0.411694</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-1.060225</td>\n",
       "      <td>-1.232955</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2.390672</td>\n",
       "      <td>0.081535</td>\n",
       "      <td>16.151029</td>\n",
       "      <td>2.390672</td>\n",
       "      <td>0.081535</td>\n",
       "      <td>16.151029</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-1.085363</td>\n",
       "      <td>-1.262106</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2.427531</td>\n",
       "      <td>0.095641</td>\n",
       "      <td>71.735419</td>\n",
       "      <td>2.427531</td>\n",
       "      <td>0.095641</td>\n",
       "      <td>71.735419</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-1.121018</td>\n",
       "      <td>-1.292234</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>2.857746</td>\n",
       "      <td>0.169634</td>\n",
       "      <td>2.960155</td>\n",
       "      <td>2.857746</td>\n",
       "      <td>0.169634</td>\n",
       "      <td>2.960155</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-1.155190</td>\n",
       "      <td>-1.307788</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>3.004110</td>\n",
       "      <td>0.128759</td>\n",
       "      <td>0.312011</td>\n",
       "      <td>3.004110</td>\n",
       "      <td>0.128759</td>\n",
       "      <td>0.312011</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val              eval_metric  \\\n",
       "0       NeuralNetTorch   -1.030848  -1.196313  root_mean_squared_error   \n",
       "1  WeightedEnsemble_L2   -1.031015  -1.195992  root_mean_squared_error   \n",
       "2      NeuralNetFastAI   -1.031634  -1.196416  root_mean_squared_error   \n",
       "3              XGBoost   -1.032005  -1.196237  root_mean_squared_error   \n",
       "4        ExtraTreesMSE   -1.060225  -1.232955  root_mean_squared_error   \n",
       "5      RandomForestMSE   -1.085363  -1.262106  root_mean_squared_error   \n",
       "6       KNeighborsUnif   -1.121018  -1.292234  root_mean_squared_error   \n",
       "7       KNeighborsDist   -1.155190  -1.307788  root_mean_squared_error   \n",
       "\n",
       "   pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  \\\n",
       "0        0.249814       0.016949   43.001672                 0.249814   \n",
       "1        4.022845       0.182707  198.020059                 0.004716   \n",
       "2        0.739340       0.033155  154.282954                 0.739340   \n",
       "3        0.024865       0.003421    0.411694                 0.024865   \n",
       "4        2.390672       0.081535   16.151029                 2.390672   \n",
       "5        2.427531       0.095641   71.735419                 2.427531   \n",
       "6        2.857746       0.169634    2.960155                 2.857746   \n",
       "7        3.004110       0.128759    0.312011                 3.004110   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.016949          43.001672            1       True   \n",
       "1                0.000423           0.011728            2       True   \n",
       "2                0.033155         154.282954            1       True   \n",
       "3                0.003421           0.411694            1       True   \n",
       "4                0.081535          16.151029            1       True   \n",
       "5                0.095641          71.735419            1       True   \n",
       "6                0.169634           2.960155            1       True   \n",
       "7                0.128759           0.312011            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          7  \n",
       "1          8  \n",
       "2          5  \n",
       "3          6  \n",
       "4          4  \n",
       "5          3  \n",
       "6          1  \n",
       "7          2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 6 features using 5000 rows with 5 shuffle sets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t14.16s\t= Expected runtime (2.83s per shuffle set)\n",
      "\t11.63s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BLACK_OR_AFRICAN_AMERICAN</th>\n",
       "      <td>0.028463</td>\n",
       "      <td>0.006865</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>5</td>\n",
       "      <td>0.042598</td>\n",
       "      <td>0.014327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HISPANIC_OR_LATINO</th>\n",
       "      <td>0.027285</td>\n",
       "      <td>0.004856</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>5</td>\n",
       "      <td>0.037285</td>\n",
       "      <td>0.017286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHITE</th>\n",
       "      <td>0.026682</td>\n",
       "      <td>0.006188</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>5</td>\n",
       "      <td>0.039423</td>\n",
       "      <td>0.013940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASIAN</th>\n",
       "      <td>0.025025</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>5</td>\n",
       "      <td>0.040465</td>\n",
       "      <td>0.009586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMERICAN_INDIAN_AND_ALASKA_NATIVE</th>\n",
       "      <td>0.015362</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>5</td>\n",
       "      <td>0.032951</td>\n",
       "      <td>-0.002227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NATIVE_HAWAIIAN_AND_OTHER_PACIFIC_ISLANDER</th>\n",
       "      <td>0.001291</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.006769</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>-0.000119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            importance    stddev   p_value  n  \\\n",
       "BLACK_OR_AFRICAN_AMERICAN                     0.028463  0.006865  0.000376  5   \n",
       "HISPANIC_OR_LATINO                            0.027285  0.004856  0.000116  5   \n",
       "WHITE                                         0.026682  0.006188  0.000324  5   \n",
       "ASIAN                                         0.025025  0.007498  0.000862  5   \n",
       "AMERICAN_INDIAN_AND_ALASKA_NATIVE             0.015362  0.008542  0.007924  5   \n",
       "NATIVE_HAWAIIAN_AND_OTHER_PACIFIC_ISLANDER    0.001291  0.000685  0.006769  5   \n",
       "\n",
       "                                            p99_high   p99_low  \n",
       "BLACK_OR_AFRICAN_AMERICAN                   0.042598  0.014327  \n",
       "HISPANIC_OR_LATINO                          0.037285  0.017286  \n",
       "WHITE                                       0.039423  0.013940  \n",
       "ASIAN                                       0.040465  0.009586  \n",
       "AMERICAN_INDIAN_AND_ALASKA_NATIVE           0.032951 -0.002227  \n",
       "NATIVE_HAWAIIAN_AND_OTHER_PACIFIC_ISLANDER  0.002702 -0.000119  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(train_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
